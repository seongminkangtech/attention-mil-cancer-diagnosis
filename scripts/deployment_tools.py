#!/usr/bin/env python3
"""
ë°°í¬ ë„êµ¬ í†µí•© ìŠ¤í¬ë¦½íŠ¸

Docker ë¹Œë“œ, Kubernetes ë°°í¬, ëª¨ë¸ ê²€ì¦ ë“± ë°°í¬ ê´€ë ¨ ëª¨ë“  ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import argparse
import os
import sys
import subprocess
import yaml
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging
import shutil

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from configs import AppConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DockerManager:
    """Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.project_root = Path(__file__).parent.parent
        
    def build_image(self, tag: str = None, dockerfile: str = None, 
                   build_args: Dict[str, str] = None) -> bool:
        """Docker ì´ë¯¸ì§€ ë¹Œë“œ"""
        try:
            tag = tag or f"attention-mil:{time.strftime('%Y%m%d-%H%M%S')}"
            dockerfile = dockerfile or "Dockerfile"
            build_args = build_args or {}
            
            logger.info(f"ğŸ³ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì‹œì‘: {tag}")
            
            # ê¸°ë³¸ ë¹Œë“œ ì¸ìˆ˜
            default_args = {
                'PROJECT_NAME': 'attention-mil',
                'PYTHON_VERSION': '3.9',
                'CUDA_VERSION': '11.8'
            }
            default_args.update(build_args)
            
            # docker build ëª…ë ¹ì–´ êµ¬ì„±
            cmd = [
                'docker', 'build',
                '-t', tag,
                '-f', dockerfile,
                '.'
            ]
            
            # ë¹Œë“œ ì¸ìˆ˜ ì¶”ê°€
            for key, value in default_args.items():
                cmd.extend(['--build-arg', f'{key}={value}'])
            
            logger.info(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
            
            # ë¹Œë“œ ì‹¤í–‰
            result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"âœ… Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ: {tag}")
                return True
            else:
                logger.error(f"âŒ Docker ë¹Œë“œ ì‹¤íŒ¨: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"Docker ë¹Œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def push_image(self, tag: str, registry: str = None) -> bool:
        """Docker ì´ë¯¸ì§€ í‘¸ì‹œ"""
        try:
            if registry:
                full_tag = f"{registry}/{tag}"
                # ì´ë¯¸ì§€ íƒœê·¸ ë³€ê²½
                subprocess.run(['docker', 'tag', tag, full_tag], check=True)
                tag = full_tag
            
            logger.info(f"ğŸ“¤ Docker ì´ë¯¸ì§€ í‘¸ì‹œ ì‹œì‘: {tag}")
            
            result = subprocess.run(['docker', 'push', tag], capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"âœ… Docker ì´ë¯¸ì§€ í‘¸ì‹œ ì™„ë£Œ: {tag}")
                return True
            else:
                logger.error(f"âŒ Docker í‘¸ì‹œ ì‹¤íŒ¨: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"Docker í‘¸ì‹œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def run_container(self, image: str, name: str = None, 
                     ports: Dict[str, str] = None, env_vars: Dict[str, str] = None) -> bool:
        """Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰"""
        try:
            name = name or f"attention-mil-{int(time.time())}"
            ports = ports or {'8000': '8000'}
            env_vars = env_vars or {}
            
            logger.info(f"ğŸš€ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œì‘: {name}")
            
            cmd = ['docker', 'run', '-d', '--name', name]
            
            # í¬íŠ¸ ë§¤í•‘
            for host_port, container_port in ports.items():
                cmd.extend(['-p', f'{host_port}:{container_port}'])
            
            # í™˜ê²½ ë³€ìˆ˜
            for key, value in env_vars.items():
                cmd.extend(['-e', f'{key}={value}'])
            
            cmd.extend([image])
            
            logger.info(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info(f"âœ… Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì™„ë£Œ: {name}")
                return True
            else:
                logger.error(f"âŒ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False


class KubernetesManager:
    """Kubernetes ë°°í¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.k8s_dir = Path(__file__).parent.parent / "k8s"
        
    def deploy_to_namespace(self, namespace: str = "dev", 
                           config_files: List[str] = None) -> bool:
        """Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë°°í¬"""
        try:
            if not config_files:
                config_files = ['namespace.yaml', 'configmap.yaml', 'secret.yaml', 'deployment.yaml']
            
            logger.info(f"â˜¸ï¸ Kubernetes ë°°í¬ ì‹œì‘: {namespace}")
            
            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
            namespace_file = self.k8s_dir / namespace / "namespace.yaml"
            if namespace_file.exists():
                subprocess.run(['kubectl', 'apply', '-f', str(namespace_file)], check=True)
                logger.info(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±: {namespace}")
            
            # ì„¤ì • íŒŒì¼ë“¤ ë°°í¬
            for config_file in config_files:
                file_path = self.k8s_dir / namespace / config_file
                if file_path.exists():
                    subprocess.run(['kubectl', 'apply', '-f', str(file_path)], check=True)
                    logger.info(f"ì„¤ì • íŒŒì¼ ë°°í¬: {config_file}")
                else:
                    logger.warning(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {config_file}")
            
            logger.info(f"âœ… Kubernetes ë°°í¬ ì™„ë£Œ: {namespace}")
            return True
            
        except Exception as e:
            logger.error(f"Kubernetes ë°°í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def check_deployment_status(self, namespace: str = "dev") -> Dict[str, Any]:
        """ë°°í¬ ìƒíƒœ í™•ì¸"""
        try:
            logger.info(f"ğŸ” ë°°í¬ ìƒíƒœ í™•ì¸: {namespace}")
            
            # íŒŒë“œ ìƒíƒœ í™•ì¸
            result = subprocess.run(
                ['kubectl', 'get', 'pods', '-n', namespace, '-o', 'json'],
                capture_output=True, text=True, check=True
            )
            
            pods_info = json.loads(result.stdout)
            
            # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            result = subprocess.run(
                ['kubectl', 'get', 'services', '-n', namespace, '-o', 'json'],
                capture_output=True, text=True, check=True
            )
            
            services_info = json.loads(result.stdout)
            
            return {
                'namespace': namespace,
                'pods': pods_info,
                'services': services_info,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            logger.error(f"ë°°í¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {}
    
    def scale_deployment(self, namespace: str, deployment: str, replicas: int) -> bool:
        """ë°°í¬ ìŠ¤ì¼€ì¼ë§"""
        try:
            logger.info(f"ğŸ“ˆ ë°°í¬ ìŠ¤ì¼€ì¼ë§: {deployment} -> {replicas} replicas")
            
            subprocess.run([
                'kubectl', 'scale', 'deployment', deployment,
                f'--replicas={replicas}', '-n', namespace
            ], check=True)
            
            logger.info(f"âœ… ë°°í¬ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {deployment}")
            return True
            
        except Exception as e:
            logger.error(f"ë°°í¬ ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}")
            return False


class ModelValidator:
    """ëª¨ë¸ ê²€ì¦ ë° ì„±ëŠ¥ ì¸¡ì • í´ë˜ìŠ¤"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        
    def validate_model_performance(self, model_path: str, 
                                 test_data_path: str = None) -> Dict[str, Any]:
        """ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦"""
        try:
            logger.info(f"ğŸ” ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì‹œì‘: {model_path}")
            
            # ëª¨ë¸ ë¡œë“œ
            import torch
            from src.models.attention_mil import AttentionMIL
            
            model = AttentionMIL(
                num_classes=self.config.attention_mil.num_classes,
                feature_extractor_config=self.config.attention_mil.feature_extractor,
                attention_config=self.config.attention_mil.attention
            )
            
            checkpoint = torch.load(model_path, map_location='cpu')
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model.eval()
            
            # ëª¨ë¸ í¬ê¸° ê³„ì‚°
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            dummy_input = torch.randn(1, 3, 224, 224)
            
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            model = model.to(device)
            dummy_input = dummy_input.to(device)
            
            # ì›Œë°ì—…
            with torch.no_grad():
                for _ in range(10):
                    _ = model(dummy_input)
            
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            with torch.no_grad():
                for _ in range(100):
                    _ = model(dummy_input)
            end_time = time.time()
            
            avg_inference_time = (end_time - start_time) / 100
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / 1024**2  # MB
                memory_reserved = torch.cuda.memory_reserved() / 1024**2    # MB
            else:
                memory_allocated = 0
                memory_reserved = 0
            
            results = {
                'model_path': model_path,
                'total_parameters': total_params,
                'trainable_parameters': trainable_params,
                'model_size_mb': os.path.getsize(model_path) / 1024**2,
                'avg_inference_time_ms': avg_inference_time * 1000,
                'device': str(device),
                'memory_allocated_mb': memory_allocated,
                'memory_reserved_mb': memory_reserved,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            logger.info("âœ… ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì™„ë£Œ")
            return results
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {}
    
    def compare_models(self, model_paths: List[str]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        logger.info("ğŸ” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
        
        comparison_results = {}
        
        for model_path in model_paths:
            if os.path.exists(model_path):
                result = self.validate_model_performance(model_path)
                if result:
                    comparison_results[os.path.basename(model_path)] = result
        
        # ì„±ëŠ¥ ìˆœìœ„ ê²°ì •
        if comparison_results:
            sorted_models = sorted(
                comparison_results.items(),
                key=lambda x: x[1]['avg_inference_time_ms']
            )
            
            comparison_results['ranking'] = [
                {'model': name, 'inference_time': data['avg_inference_time_ms']}
                for name, data in sorted_models
            ]
        
        return comparison_results


class DeploymentOrchestrator:
    """ì „ì²´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì¡°ìœ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.docker_manager = DockerManager(config)
        self.k8s_manager = KubernetesManager(config)
        self.model_validator = ModelValidator(config)
        
    def full_deployment_pipeline(self, model_path: str, 
                                image_tag: str = None,
                                namespace: str = "dev") -> bool:
        """ì „ì²´ ë°°í¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ ì „ì²´ ë°°í¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # 1. ëª¨ë¸ ê²€ì¦
            logger.info("1ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦")
            validation_result = self.model_validator.validate_model_performance(model_path)
            if not validation_result:
                logger.error("ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨")
                return False
            
            # 2. Docker ì´ë¯¸ì§€ ë¹Œë“œ
            logger.info("2ï¸âƒ£ Docker ì´ë¯¸ì§€ ë¹Œë“œ")
            if not self.docker_manager.build_image(tag=image_tag):
                logger.error("Docker ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨")
                return False
            
            # 3. Kubernetes ë°°í¬
            logger.info("3ï¸âƒ£ Kubernetes ë°°í¬")
            if not self.k8s_manager.deploy_to_namespace(namespace):
                logger.error("Kubernetes ë°°í¬ ì‹¤íŒ¨")
                return False
            
            # 4. ë°°í¬ ìƒíƒœ í™•ì¸
            logger.info("4ï¸âƒ£ ë°°í¬ ìƒíƒœ í™•ì¸")
            time.sleep(30)  # ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
            status = self.k8s_manager.check_deployment_status(namespace)
            
            logger.info("âœ… ì „ì²´ ë°°í¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë°°í¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ë°°í¬ ë„êµ¬ í†µí•© ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--action", required=True,
                       choices=["docker-build", "docker-push", "docker-run", "k8s-deploy", 
                               "k8s-status", "k8s-scale", "validate-model", "compare-models", 
                               "full-pipeline"],
                       help="ìˆ˜í–‰í•  ì‘ì—…")
    parser.add_argument("--config", default="configs/attention_mil.yaml",
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--tag", help="Docker ì´ë¯¸ì§€ íƒœê·¸")
    parser.add_argument("--namespace", default="dev", help="Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤")
    parser.add_argument("--model-path", help="ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model-paths", nargs='+', help="ë¹„êµí•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œë“¤")
    parser.add_argument("--replicas", type=int, help="ë°°í¬ ë³µì œë³¸ ìˆ˜")
    parser.add_argument("--deployment", help="ë°°í¬ ì´ë¦„")
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    try:
        config = AppConfig.from_yaml(args.config)
    except Exception as e:
        logger.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
    orchestrator = DeploymentOrchestrator(config)
    
    if args.action == "docker-build":
        # Docker ì´ë¯¸ì§€ ë¹Œë“œ
        orchestrator.docker_manager.build_image(tag=args.tag)
    
    elif args.action == "docker-push":
        # Docker ì´ë¯¸ì§€ í‘¸ì‹œ
        if not args.tag:
            logger.error("--tag ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        orchestrator.docker_manager.push_image(args.tag)
    
    elif args.action == "docker-run":
        # Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
        if not args.tag:
            logger.error("--tag ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        orchestrator.docker_manager.run_container(args.tag)
    
    elif args.action == "k8s-deploy":
        # Kubernetes ë°°í¬
        orchestrator.k8s_manager.deploy_to_namespace(args.namespace)
    
    elif args.action == "k8s-status":
        # Kubernetes ë°°í¬ ìƒíƒœ í™•ì¸
        status = orchestrator.k8s_manager.check_deployment_status(args.namespace)
        print(json.dumps(status, indent=2, ensure_ascii=False))
    
    elif args.action == "k8s-scale":
        # Kubernetes ë°°í¬ ìŠ¤ì¼€ì¼ë§
        if not args.deployment or not args.replicas:
            logger.error("--deploymentì™€ --replicas ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        orchestrator.k8s_manager.scale_deployment(args.namespace, args.deployment, args.replicas)
    
    elif args.action == "validate-model":
        # ëª¨ë¸ ê²€ì¦
        if not args.model_path:
            logger.error("--model-path ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        result = orchestrator.model_validator.validate_model_performance(args.model_path)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif args.action == "compare-models":
        # ëª¨ë¸ ë¹„êµ
        if not args.model_paths:
            logger.error("--model-paths ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        result = orchestrator.model_validator.compare_models(args.model_paths)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif args.action == "full-pipeline":
        # ì „ì²´ ë°°í¬ íŒŒì´í”„ë¼ì¸
        if not args.model_path:
            logger.error("--model-path ì¸ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        orchestrator.full_deployment_pipeline(args.model_path, args.tag, args.namespace)


if __name__ == "__main__":
    main()

