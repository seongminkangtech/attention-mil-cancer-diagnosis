#!/usr/bin/env python3
"""
ONNX ëª¨ë¸ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸

ë³€í™˜ëœ ONNX ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import argparse
import os
import sys
import onnx
import onnxruntime as ort
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))


def load_onnx_model(onnx_path: str):
    """
    ONNX ëª¨ë¸ ë¡œë“œ
    
    Args:
        onnx_path (str): ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        onnx.ModelProto: ë¡œë“œëœ ONNX ëª¨ë¸
    """
    print(f"ğŸ“¥ ONNX ëª¨ë¸ ë¡œë“œ ì¤‘...")
    print(f"   - íŒŒì¼ ê²½ë¡œ: {onnx_path}")
    
    try:
        model = onnx.load(onnx_path)
        print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        print(f"   - ëª¨ë¸ ë²„ì „: {model.ir_version}")
        print(f"   - Opset ë²„ì „: {model.opset_import[0].version}")
        print(f"   - í”„ë¡œë“€ì„œ: {model.producer_name}")
        print(f"   - ì…ë ¥ ìˆ˜: {len(model.graph.input)}")
        print(f"   - ì¶œë ¥ ìˆ˜: {len(model.graph.output)}")
        print(f"   - ë…¸ë“œ ìˆ˜: {len(model.graph.node)}")
        
        return model
        
    except Exception as e:
        print(f"âŒ ONNX ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def analyze_onnx_model(model: onnx.ModelProto):
    """
    ONNX ëª¨ë¸ ë¶„ì„
    
    Args:
        model (onnx.ModelProto): ë¶„ì„í•  ONNX ëª¨ë¸
    """
    print(f"ğŸ” ONNX ëª¨ë¸ ë¶„ì„ ì¤‘...")
    
    # ì…ë ¥ ì •ë³´
    print(f"   ğŸ“¥ ì…ë ¥ ì •ë³´:")
    for i, input_info in enumerate(model.graph.input):
        print(f"     - ì…ë ¥ {i}: {input_info.name}")
        if input_info.type.tensor_type.shape.dim:
            shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' for dim in input_info.type.tensor_type.shape.dim]
            print(f"       í˜•íƒœ: {shape}")
    
    # ì¶œë ¥ ì •ë³´
    print(f"   ğŸ“¤ ì¶œë ¥ ì •ë³´:")
    for i, output_info in enumerate(model.graph.output):
        print(f"     - ì¶œë ¥ {i}: {output_info.name}")
        if output_info.type.tensor_type.shape.dim:
            shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' for dim in output_info.type.tensor_type.shape.dim]
            print(f"       í˜•íƒœ: {shape}")
    
    # ì—°ì‚°ì í†µê³„
    op_types = {}
    for node in model.graph.node:
        op_type = node.op_type
        op_types[op_type] = op_types.get(op_type, 0) + 1
    
    print(f"   âš™ï¸ ì—°ì‚°ì í†µê³„:")
    for op_type, count in sorted(op_types.items()):
        print(f"     - {op_type}: {count}ê°œ")


def optimize_onnx_model(input_path: str, output_path: str, optimization_level: str = 'all'):
    """
    ONNX ëª¨ë¸ ìµœì í™”
    
    Args:
        input_path (str): ì…ë ¥ ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        output_path (str): ì¶œë ¥ ìµœì í™”ëœ ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        optimization_level (str): ìµœì í™” ë ˆë²¨ ('basic', 'extended', 'all')
    """
    print(f"ğŸ”„ ONNX ëª¨ë¸ ìµœì í™” ì¤‘...")
    print(f"   - ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"   - ì¶œë ¥ íŒŒì¼: {output_path}")
    print(f"   - ìµœì í™” ë ˆë²¨: {optimization_level}")
    
    try:
        # ONNX ëª¨ë¸ ë¡œë“œ
        model = load_onnx_model(input_path)
        
        # ëª¨ë¸ ë¶„ì„
        analyze_onnx_model(model)
        
        # ìµœì í™” ìˆ˜í–‰
        if optimization_level == 'basic':
            # ê¸°ë³¸ ìµœì í™”: ê·¸ë˜í”„ ìµœì í™”
            print(f"   ğŸ”§ ê¸°ë³¸ ìµœì í™” ìˆ˜í–‰ ì¤‘...")
            optimized_model = onnx.optimizer.optimize(model)
            
        elif optimization_level == 'extended':
            # í™•ì¥ ìµœì í™”: ì¶”ê°€ ê·¸ë˜í”„ ìµœì í™”
            print(f"   ğŸ”§ í™•ì¥ ìµœì í™” ìˆ˜í–‰ ì¤‘...")
            optimized_model = onnx.optimizer.optimize(model)
            # ì¶”ê°€ ìµœì í™” ì˜µì…˜ë“¤
            optimized_model = onnx.shape_inference.infer_shapes(optimized_model)
            
        else:  # 'all'
            # ì „ì²´ ìµœì í™”: ëª¨ë“  ìµœì í™” ê¸°ë²• ì ìš©
            print(f"   ğŸ”§ ì „ì²´ ìµœì í™” ìˆ˜í–‰ ì¤‘...")
            optimized_model = onnx.optimizer.optimize(model)
            optimized_model = onnx.shape_inference.infer_shapes(optimized_model)
            
            # ì¶”ê°€ ìµœì í™”: ë¶ˆí•„ìš”í•œ ë…¸ë“œ ì œê±°
            optimized_model = onnx.optimizer.optimize(optimized_model, ['eliminate_identity'])
        
        # ìµœì í™”ëœ ëª¨ë¸ ì €ì¥
        onnx.save(optimized_model, output_path)
        
        # ìµœì í™” ê²°ê³¼ ë¶„ì„
        print(f"âœ… ìµœì í™” ì™„ë£Œ!")
        print(f"   - ì›ë³¸ íŒŒì¼ í¬ê¸°: {os.path.getsize(input_path) / (1024*1024):.2f} MB")
        print(f"   - ìµœì í™” íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / (1024*1024):.2f} MB")
        
        size_reduction = (1 - os.path.getsize(output_path) / os.path.getsize(input_path)) * 100
        print(f"   - í¬ê¸° ê°ì†Œ: {size_reduction:.1f}%")
        
        # ìµœì í™”ëœ ëª¨ë¸ ë¶„ì„
        print(f"ğŸ” ìµœì í™”ëœ ëª¨ë¸ ë¶„ì„:")
        analyze_onnx_model(optimized_model)
        
    except Exception as e:
        print(f"âŒ ONNX ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨: {e}")
        raise


def benchmark_onnx_model(onnx_path: str, num_runs: int = 100):
    """
    ONNX ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    
    Args:
        onnx_path (str): ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        num_runs (int): ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ íšŸìˆ˜
    """
    print(f"âš¡ ONNX ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
    print(f"   - ëª¨ë¸ íŒŒì¼: {onnx_path}")
    print(f"   - ì‹¤í–‰ íšŸìˆ˜: {num_runs}")
    
    try:
        # ONNX Runtime ì„¸ì…˜ ìƒì„±
        session = ort.InferenceSession(onnx_path)
        
        # ì…ë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        input_info = session.get_inputs()[0]
        input_name = input_info.name
        input_shape = input_info.shape
        
        print(f"   ğŸ“¥ ì…ë ¥ ì •ë³´:")
        print(f"     - ì´ë¦„: {input_name}")
        print(f"     - í˜•íƒœ: {input_shape}")
        
        # ë”ë¯¸ ì…ë ¥ ë°ì´í„° ìƒì„±
        if input_shape[0] == 0:  # ë™ì  ë°°ì¹˜ í¬ê¸°
            input_shape = (1,) + tuple(input_shape[1:])
        
        dummy_input = np.random.randn(*input_shape).astype(np.float32)
        
        # ì›Œë°ì—…
        print(f"   ğŸ”¥ ì›Œë°ì—… ì¤‘...")
        for _ in range(10):
            session.run(None, {input_name: dummy_input})
        
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        print(f"   ğŸƒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
        import time
        
        times = []
        for i in range(num_runs):
            start_time = time.time()
            session.run(None, {input_name: dummy_input})
            end_time = time.time()
            times.append(end_time - start_time)
            
            if (i + 1) % 20 == 0:
                print(f"     - ì§„í–‰ë¥ : {i + 1}/{num_runs}")
        
        # ê²°ê³¼ ë¶„ì„
        times = np.array(times)
        avg_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)
        
        print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print(f"   ğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
        print(f"     - í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time*1000:.2f} ms")
        print(f"     - í‘œì¤€í¸ì°¨: {std_time*1000:.2f} ms")
        print(f"     - ìµœì†Œ ì‹œê°„: {min_time*1000:.2f} ms")
        print(f"     - ìµœëŒ€ ì‹œê°„: {max_time*1000:.2f} ms")
        print(f"     - FPS: {1/avg_time:.1f}")
        
    except Exception as e:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ONNX ëª¨ë¸ ìµœì í™”')
    parser.add_argument('--input_path', type=str, required=True,
                       help='ì…ë ¥ ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output_path', type=str, required=True,
                       help='ì¶œë ¥ ìµœì í™”ëœ ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--optimization_level', type=str, default='all',
                       choices=['basic', 'extended', 'all'],
                       help='ìµœì í™” ë ˆë²¨ (ê¸°ë³¸ê°’: all)')
    parser.add_argument('--benchmark', action='store_true',
                       help='ìµœì í™” í›„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰')
    parser.add_argument('--num_runs', type=int, default=100,
                       help='ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ íšŸìˆ˜ (ê¸°ë³¸ê°’: 100)')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ONNX ëª¨ë¸ ìµœì í™” ì‹œì‘")
    print(f"   - ì…ë ¥ íŒŒì¼: {args.input_path}")
    print(f"   - ì¶œë ¥ íŒŒì¼: {args.output_path}")
    print(f"   - ìµœì í™” ë ˆë²¨: {args.optimization_level}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(args.output_path), exist_ok=True)
    
    try:
        # ONNX ëª¨ë¸ ìµœì í™”
        optimize_onnx_model(
            input_path=args.input_path,
            output_path=args.output_path,
            optimization_level=args.optimization_level
        )
        
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì„ íƒì‚¬í•­)
        if args.benchmark:
            print(f"\n" + "="*50)
            print(f"ğŸ“Š ì›ë³¸ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬")
            print(f"="*50)
            benchmark_onnx_model(args.input_path, args.num_runs)
            
            print(f"\n" + "="*50)
            print(f"ğŸ“Š ìµœì í™”ëœ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬")
            print(f"="*50)
            benchmark_onnx_model(args.output_path, args.num_runs)
        
        print(f"ğŸ‰ ONNX ëª¨ë¸ ìµœì í™” ì™„ë£Œ!")
        print(f"   - ìµœì í™”ëœ íŒŒì¼: {args.output_path}")
        
    except Exception as e:
        print(f"âŒ ìµœì í™” ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 